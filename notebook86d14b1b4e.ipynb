{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba2be64",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-28T09:33:44.556489Z",
     "iopub.status.busy": "2025-05-28T09:33:44.556128Z",
     "iopub.status.idle": "2025-05-28T09:33:44.572197Z",
     "shell.execute_reply": "2025-05-28T09:33:44.571027Z"
    },
    "papermill": {
     "duration": 0.023135,
     "end_time": "2025-05-28T09:33:44.573933",
     "exception": false,
     "start_time": "2025-05-28T09:33:44.550798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Folder not found: /kaggle/input/PAF-data/paroxysmal-atrial-fibrillation-events-detection-from-dynamic-ecg-recordings-the-4th-china-physiological-signal-challenge-2021-1.0.0/Training_set_I\n",
      "‚ö†Ô∏è Folder not found: /kaggle/input/PAF-data/paroxysmal-atrial-fibrillation-events-detection-from-dynamic-ecg-recordings-the-4th-china-physiological-signal-challenge-2021-1.0.0/Training_set_II\n",
      "\n",
      "‚úÖ Done! Files segregated:\n",
      "AF: 0 records\n",
      "PAF: 0 records\n",
      "NonAF: 0 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ‚úÖ Extract AF label from header file\n",
    "def get_af_label(hea_path):\n",
    "    try:\n",
    "        with open(hea_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line_lower = line.lower()\n",
    "                if \"paroxysmal atrial fibrillation\" in line_lower:\n",
    "                    return \"PAF\"\n",
    "                elif \"persistent atrial fibrillation\" in line_lower:\n",
    "                    return \"AF\"\n",
    "                elif \"non atrial fibrillation\" in line_lower:\n",
    "                    return \"NonAF\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {hea_path}: {e}\")\n",
    "    return \"Unknown\"\n",
    "\n",
    "# ‚úÖ Input base path (updated folder name to PAF-data)\n",
    "base_input_path = \"/kaggle/input/PAF-data/paroxysmal-atrial-fibrillation-events-detection-from-dynamic-ecg-recordings-the-4th-china-physiological-signal-challenge-2021-1.0.0\"\n",
    "training_sets = ['Training_set_I', 'Training_set_II']\n",
    "input_paths = [os.path.join(base_input_path, ts) for ts in training_sets]\n",
    "\n",
    "# ‚úÖ Output base path (Kaggle working directory)\n",
    "output_base_path = \"/kaggle/working\"\n",
    "target_labels = ['AF', 'PAF', 'NonAF']\n",
    "\n",
    "# ‚úÖ Create output folders\n",
    "for label in target_labels:\n",
    "    os.makedirs(os.path.join(output_base_path, label), exist_ok=True)\n",
    "\n",
    "# ‚úÖ Dictionary to count saved files\n",
    "file_counts = {label: 0 for label in target_labels}\n",
    "\n",
    "# ‚úÖ Process both training sets\n",
    "for set_path in input_paths:\n",
    "    if not os.path.isdir(set_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {set_path}\")\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(set_path):\n",
    "        if file.endswith('.hea'):\n",
    "            base_name = file[:-4]\n",
    "            hea_path = os.path.join(set_path, file)\n",
    "            label = get_af_label(hea_path)\n",
    "\n",
    "            if label in target_labels:\n",
    "                for ext in ['.hea', '.atr', '.dat']:\n",
    "                    src = os.path.join(set_path, base_name + ext)\n",
    "                    dest = os.path.join(output_base_path, label, base_name + ext)\n",
    "\n",
    "                    if os.path.exists(src):\n",
    "                        shutil.copy2(src, dest)\n",
    "                file_counts[label] += 1\n",
    "            else:\n",
    "                print(f\"‚ùì Skipped unlabelled: {file}\")\n",
    "\n",
    "# ‚úÖ Print summary\n",
    "print(\"\\n‚úÖ Done! Files segregated:\")\n",
    "for label in target_labels:\n",
    "    print(f\"{label}: {file_counts[label]} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882fbe1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:33:44.582225Z",
     "iopub.status.busy": "2025-05-28T09:33:44.581915Z",
     "iopub.status.idle": "2025-05-28T09:33:44.587290Z",
     "shell.execute_reply": "2025-05-28T09:33:44.586310Z"
    },
    "papermill": {
     "duration": 0.011304,
     "end_time": "2025-05-28T09:33:44.589049",
     "exception": false,
     "start_time": "2025-05-28T09:33:44.577745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_input_path = \"/kaggle/input/PAF-data\"\n",
    "\n",
    "# List all subdirectories\n",
    "for root, dirs, files in os.walk(base_input_path):\n",
    "    print(\"üìÅ\", root)\n",
    "    for d in dirs:\n",
    "        print(\"   ‚îî‚îÄ‚îÄ\", d)\n",
    "    break  # Only list top-level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9df59b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:33:44.597131Z",
     "iopub.status.busy": "2025-05-28T09:33:44.596808Z",
     "iopub.status.idle": "2025-05-28T09:33:44.602404Z",
     "shell.execute_reply": "2025-05-28T09:33:44.601394Z"
    },
    "papermill": {
     "duration": 0.011381,
     "end_time": "2025-05-28T09:33:44.604026",
     "exception": false,
     "start_time": "2025-05-28T09:33:44.592645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Kaggle Input Folders:\n",
      " - paf-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"üì¶ Kaggle Input Folders:\")\n",
    "for d in os.listdir(\"/kaggle/input\"):\n",
    "    print(\" -\", d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae8beb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:33:44.612207Z",
     "iopub.status.busy": "2025-05-28T09:33:44.611849Z",
     "iopub.status.idle": "2025-05-28T09:33:44.621843Z",
     "shell.execute_reply": "2025-05-28T09:33:44.620388Z"
    },
    "papermill": {
     "duration": 0.016194,
     "end_time": "2025-05-28T09:33:44.623632",
     "exception": false,
     "start_time": "2025-05-28T09:33:44.607438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Listing folders inside: /kaggle/input/paf-data\n",
      "üìÅ /kaggle/input/paf-data\n",
      "   ‚îî‚îÄ‚îÄ PAF\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_input_path = \"/kaggle/input/paf-data\"\n",
    "\n",
    "print(f\"üìÅ Listing folders inside: {base_input_path}\")\n",
    "for root, dirs, files in os.walk(base_input_path):\n",
    "    print(\"üìÅ\", root)\n",
    "    for d in dirs:\n",
    "        print(\"   ‚îî‚îÄ‚îÄ\", d)\n",
    "    break  # Only show top-level structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a697d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:33:44.632246Z",
     "iopub.status.busy": "2025-05-28T09:33:44.631309Z",
     "iopub.status.idle": "2025-05-28T09:34:19.627501Z",
     "shell.execute_reply": "2025-05-28T09:34:19.626444Z"
    },
    "papermill": {
     "duration": 35.004675,
     "end_time": "2025-05-28T09:34:19.631748",
     "exception": false,
     "start_time": "2025-05-28T09:33:44.627073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Done! Files segregated into AF, PAF, and NonAF folders per training set:\n",
      "\n",
      "üìÇ Training_set_I:\n",
      "  AF: 153 records\n",
      "  PAF: 96 records\n",
      "  NonAF: 470 records\n",
      "  Unknown: 0 records\n",
      "\n",
      "üìÇ Training_set_II:\n",
      "  AF: 322 records\n",
      "  PAF: 133 records\n",
      "  NonAF: 251 records\n",
      "  Unknown: 0 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# ‚úÖ Correct base path based on Kaggle folder structure\n",
    "base_input_path = \"/kaggle/input/paf-data/PAF\"\n",
    "training_sets = [\"Training_set_I\", \"Training_set_II\"]\n",
    "output_base = \"/kaggle/working/segregated_data\"\n",
    "\n",
    "# ‚úÖ Function to determine category from .hea file\n",
    "def get_af_label(hea_path):\n",
    "    try:\n",
    "        with open(hea_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line_lower = line.lower()\n",
    "                if \"paroxysmal atrial fibrillation\" in line_lower:\n",
    "                    return \"PAF\"\n",
    "                elif \"persistent atrial fibrillation\" in line_lower:\n",
    "                    return \"AF\"\n",
    "                elif \"non atrial fibrillation\" in line_lower:\n",
    "                    return \"NonAF\"\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {hea_path}: {e}\")\n",
    "    \n",
    "    return \"Unknown\"\n",
    "\n",
    "# ‚úÖ Process each training set independently\n",
    "global_counts = {}\n",
    "\n",
    "for ts in training_sets:\n",
    "    ts_path = os.path.join(base_input_path, ts)\n",
    "    ts_output = os.path.join(output_base, ts)\n",
    "    \n",
    "    if not os.path.exists(ts_path):\n",
    "        print(f\"‚ö†Ô∏è Folder not found: {ts_path}\")\n",
    "        continue\n",
    "\n",
    "    # Create subfolders for AF, PAF, NonAF under each training set\n",
    "    categories = [\"AF\", \"PAF\", \"NonAF\"]\n",
    "    for cat in categories:\n",
    "        os.makedirs(os.path.join(ts_output, cat), exist_ok=True)\n",
    "    \n",
    "    counts = {\"AF\": 0, \"PAF\": 0, \"NonAF\": 0, \"Unknown\": 0}\n",
    "\n",
    "    for fname in os.listdir(ts_path):\n",
    "        if fname.endswith(\".hea\"):\n",
    "            record_name = fname.replace(\".hea\", \"\")\n",
    "            hea_path = os.path.join(ts_path, record_name + \".hea\")\n",
    "            label = get_af_label(hea_path)\n",
    "\n",
    "            if label in categories:\n",
    "                dest_dir = os.path.join(ts_output, label)\n",
    "                for ext in [\".hea\", \".atr\", \".dat\"]:\n",
    "                    src = os.path.join(ts_path, record_name + ext)\n",
    "                    if os.path.exists(src):\n",
    "                        shutil.copy(src, dest_dir)\n",
    "                counts[label] += 1\n",
    "            else:\n",
    "                counts[\"Unknown\"] += 1\n",
    "\n",
    "    global_counts[ts] = counts\n",
    "\n",
    "# ‚úÖ Final report\n",
    "print(\"\\n‚úÖ Done! Files segregated into AF, PAF, and NonAF folders per training set:\")\n",
    "for ts, counts in global_counts.items():\n",
    "    print(f\"\\nüìÇ {ts}:\")\n",
    "    for label, count in counts.items():\n",
    "        print(f\"  {label}: {count} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c97ad69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:34:19.641305Z",
     "iopub.status.busy": "2025-05-28T09:34:19.640947Z",
     "iopub.status.idle": "2025-05-28T09:35:42.350186Z",
     "shell.execute_reply": "2025-05-28T09:35:42.349008Z"
    },
    "papermill": {
     "duration": 82.718894,
     "end_time": "2025-05-28T09:35:42.355074",
     "exception": false,
     "start_time": "2025-05-28T09:34:19.636180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ZIP archive created at: /kaggle/working/segregated_data.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "zip_path = \"/kaggle/working/segregated_data.zip\"\n",
    "shutil.make_archive(base_name=zip_path.replace('.zip', ''), format='zip', root_dir=output_base)\n",
    "\n",
    "print(f\"\\n‚úÖ ZIP archive created at: {zip_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da03674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:35:42.363697Z",
     "iopub.status.busy": "2025-05-28T09:35:42.363333Z",
     "iopub.status.idle": "2025-05-28T09:37:05.142628Z",
     "shell.execute_reply": "2025-05-28T09:37:05.141610Z"
    },
    "papermill": {
     "duration": 82.789021,
     "end_time": "2025-05-28T09:37:05.147524",
     "exception": false,
     "start_time": "2025-05-28T09:35:42.358503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created zip files:\n",
      " - /kaggle/working/Training_set_I.zip\n",
      " - /kaggle/working/Training_set_II.zip\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Path to the folder you want to zip\n",
    "folder_to_zip_1 = \"/kaggle/working/segregated_data/Training_set_I\"\n",
    "folder_to_zip_2 = \"/kaggle/working/segregated_data/Training_set_II\"\n",
    "\n",
    "# Output zip paths (will be saved inside /kaggle/working/)\n",
    "zip_output_1 = \"/kaggle/working/Training_set_I.zip\"\n",
    "zip_output_2 = \"/kaggle/working/Training_set_II.zip\"\n",
    "\n",
    "# Create zip files\n",
    "shutil.make_archive(zip_output_1[:-4], 'zip', folder_to_zip_1)\n",
    "shutil.make_archive(zip_output_2[:-4], 'zip', folder_to_zip_2)\n",
    "\n",
    "print(f\"‚úÖ Created zip files:\\n - {zip_output_1}\\n - {zip_output_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "428fdcb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:37:05.155696Z",
     "iopub.status.busy": "2025-05-28T09:37:05.155339Z",
     "iopub.status.idle": "2025-05-28T09:37:05.162480Z",
     "shell.execute_reply": "2025-05-28T09:37:05.161408Z"
    },
    "papermill": {
     "duration": 0.013072,
     "end_time": "2025-05-28T09:37:05.164082",
     "exception": false,
     "start_time": "2025-05-28T09:37:05.151010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in /kaggle/working/:\n",
      "['PAF', 'Training_set_II.zip', 'Training_set_I.zip', 'AF', '__notebook__.ipynb', 'segregated_data.zip', 'NonAF', 'segregated_data']\n",
      "\n",
      "Files in segregated_data/Training_set_I:\n",
      "['PAF', 'AF', 'NonAF']\n",
      "\n",
      "Files in segregated_data/Training_set_II:\n",
      "['PAF', 'AF', 'NonAF']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Files in /kaggle/working/:\")\n",
    "print(os.listdir(\"/kaggle/working/\"))\n",
    "\n",
    "print(\"\\nFiles in segregated_data/Training_set_I:\")\n",
    "print(os.listdir(\"/kaggle/working/segregated_data/Training_set_I\")[:5])\n",
    "\n",
    "print(\"\\nFiles in segregated_data/Training_set_II:\")\n",
    "print(os.listdir(\"/kaggle/working/segregated_data/Training_set_II\")[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936c4d92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:37:05.173094Z",
     "iopub.status.busy": "2025-05-28T09:37:05.172481Z",
     "iopub.status.idle": "2025-05-28T09:37:05.181562Z",
     "shell.execute_reply": "2025-05-28T09:37:05.180753Z"
    },
    "papermill": {
     "duration": 0.015189,
     "end_time": "2025-05-28T09:37:05.183065",
     "exception": false,
     "start_time": "2025-05-28T09:37:05.167876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/Training_set_I.zip' target='_blank'>/kaggle/working/Training_set_I.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/Training_set_I.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='/kaggle/working/Training_set_II.zip' target='_blank'>/kaggle/working/Training_set_II.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/Training_set_II.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import FileLink, display\n",
    "\n",
    "display(FileLink(\"/kaggle/working/Training_set_I.zip\"))\n",
    "display(FileLink(\"/kaggle/working/Training_set_II.zip\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc14ea51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:37:05.192381Z",
     "iopub.status.busy": "2025-05-28T09:37:05.192089Z",
     "iopub.status.idle": "2025-05-28T09:37:05.200237Z",
     "shell.execute_reply": "2025-05-28T09:37:05.199356Z"
    },
    "papermill": {
     "duration": 0.014212,
     "end_time": "2025-05-28T09:37:05.201603",
     "exception": false,
     "start_time": "2025-05-28T09:37:05.187391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='Training_set_I.zip' target='_blank'>Training_set_I.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/Training_set_I.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href='Training_set_II.zip' target='_blank'>Training_set_II.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/Training_set_II.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import FileLink, display\n",
    "\n",
    "display(FileLink(\"Training_set_I.zip\"))\n",
    "display(FileLink(\"Training_set_II.zip\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d24dbce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:37:05.211248Z",
     "iopub.status.busy": "2025-05-28T09:37:05.210428Z",
     "iopub.status.idle": "2025-05-28T09:37:11.546672Z",
     "shell.execute_reply": "2025-05-28T09:37:11.545397Z"
    },
    "papermill": {
     "duration": 6.342885,
     "end_time": "2025-05-28T09:37:11.548510",
     "exception": false,
     "start_time": "2025-05-28T09:37:05.205625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wfdb\r\n",
      "  Downloading wfdb-4.3.0-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.11.18)\r\n",
      "Requirement already satisfied: fsspec>=2023.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2025.3.2)\r\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from wfdb) (3.7.2)\r\n",
      "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.2.3)\r\n",
      "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from wfdb) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (1.15.2)\r\n",
      "Requirement already satisfied: soundfile>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from wfdb) (0.13.1)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.6.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (6.4.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (0.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.10.11->wfdb) (1.20.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (4.57.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (25.0)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (11.1.0)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->wfdb) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.4->wfdb) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.3->wfdb) (2025.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.8.1->wfdb) (2025.4.26)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.17.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.4->wfdb) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.4->wfdb) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.4->wfdb) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.4->wfdb) (2024.2.0)\r\n",
      "Downloading wfdb-4.3.0-py3-none-any.whl (163 kB)\r\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: wfdb\r\n",
      "Successfully installed wfdb-4.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wfdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea33e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T09:37:11.559406Z",
     "iopub.status.busy": "2025-05-28T09:37:11.559093Z",
     "iopub.status.idle": "2025-05-28T09:37:14.360178Z",
     "shell.execute_reply": "2025-05-28T09:37:14.358942Z"
    },
    "papermill": {
     "duration": 2.808409,
     "end_time": "2025-05-28T09:37:14.361768",
     "exception": false,
     "start_time": "2025-05-28T09:37:11.553359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion for Training_set_I...\n",
      "\n",
      "Starting conversion for Training_set_II...\n",
      "\n",
      "‚úÖ All conversions completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import scipy.io\n",
    "\n",
    "def convert_dat_to_mat(record_path, output_mat_path):\n",
    "    try:\n",
    "        record = wfdb.rdrecord(record_path)\n",
    "        signal_data = record.p_signal\n",
    "        scipy.io.savemat(output_mat_path, {'ecg_signal': signal_data})\n",
    "        print(f\"‚úÖ Converted {record_path} to {output_mat_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error converting {record_path}: {e}\")\n",
    "\n",
    "def batch_convert(base_input_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # List category folders like AF, PAF, NonAF\n",
    "    for category in os.listdir(base_input_folder):\n",
    "        category_path = os.path.join(base_input_folder, category)\n",
    "        if os.path.isdir(category_path):\n",
    "            # Create corresponding category folder in output\n",
    "            output_category_folder = os.path.join(output_folder, category)\n",
    "            os.makedirs(output_category_folder, exist_ok=True)\n",
    "            \n",
    "            # Now list records inside category folder\n",
    "            for record_name in os.listdir(category_path):\n",
    "                record_dir = os.path.join(category_path, record_name)\n",
    "                if os.path.isdir(record_dir):\n",
    "                    record_file_prefix = os.path.join(record_dir, record_name)\n",
    "                    output_mat_path = os.path.join(output_category_folder, record_name + \".mat\")\n",
    "                    convert_dat_to_mat(record_file_prefix, output_mat_path)\n",
    "\n",
    "# === Set your actual paths ===\n",
    "training_set_1_folder = \"/kaggle/working/segregated_data/Training_set_I\"\n",
    "training_set_2_folder = \"/kaggle/working/segregated_data/Training_set_II\"\n",
    "\n",
    "output_mat_folder_1 = \"/kaggle/working/mat_files/Training_set_I\"\n",
    "output_mat_folder_2 = \"/kaggle/working/mat_files/Training_set_II\"\n",
    "\n",
    "print(\"Starting conversion for Training_set_I...\")\n",
    "batch_convert(training_set_1_folder, output_mat_folder_1)\n",
    "\n",
    "print(\"\\nStarting conversion for Training_set_II...\")\n",
    "batch_convert(training_set_2_folder, output_mat_folder_2)\n",
    "\n",
    "print(\"\\n‚úÖ All conversions completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7517935,
     "sourceId": 11957090,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 217.369861,
   "end_time": "2025-05-28T09:37:14.989157",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-28T09:33:37.619296",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
